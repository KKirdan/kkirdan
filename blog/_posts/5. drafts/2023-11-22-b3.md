---
layout: post
title: Что такое уменьшение страданий
unixtime:
  - "1700688756"
original_date: 2023.11.23
authors:
  - К. Кирдан
show_title: true
tags:
  - аксиология_и_этика
  - рациональность
  - счастье_и_несчастье
meta_tags: черновик
importance: 10
comment: Это черновик статьи для проекта <a href="https://reducingsuffering.github.io/">Reducing Suffering</a>.<br> Статья еще не закончена!
---
В данной заметке мы постараемся популярно, но при этом достаточно подробно объяснить, что понимается под _уменьшением страданий_ (или, что обычно тоже самое, _минимизацией страданий_) в современном [(негативно) утилитарном](https://reducingsuffering.github.io/71.html) дискурсе, как он представлен в движении [эффективных альтруистов](https://reducingsuffering.github.io/78.html).

Поскольку страдания — лишь одна из многих вещей, которые могут волновать людей, тогда как стоящие за их минимизацией соображения по большей части универсальны, данный текст может помочь разобраться в некоторых вопросах [консеквенциализма](https://reducingsuffering.github.io/44.html) как такового, и утилитаризма в частности.

Мы рассмотрим такие темы как: отличия между оптимизацией в локальном и глобальном масштабах, отличия между субъективным и объективным качеством принимаемых решений, проблема выбора горизонта планирования, проблема невозможности достоверно предсказывать будущее, инструментальные ценности, комбинации цели уменьшения страданий с другими целями.

## Содержание
[1\. Страдания и их количество](#1)<br>
[2\. Что значит "уменьшение"](#2)<br>
[3\. Локальный случай](#3)<br>
[3.1. Субъективно оптимальный выбор](#3.1)<br>
[3.2. Объективное качество выбора](#3.2)<br>
[3.3\. Вероятности наступления событий](#3.3)<br>
[3.4. Время на принятие решений](#3.4)<br>
[4\. Горизонт планирования](#4)<br>
[5. Глобальный случай](#5)<br>
[5.1. Постановка задачи](#5.1)<br>
[5.2. Решение задачи](#5.2)<br>
[6. Модификации](#6)<br>
[6.1. Дополнительные цели оптимизации](#6.1)<br>
[6.2. Ограничения на способы оптимизации](#6.2)<br>
[6.3. Ограничения морального круга](#6.3)<br>
[Источники](#sources)<br>
[Что еще почитать](#further)

---
<a name="1"></a>
## 1. Страдания и их количество

В данном тексте мы не будем углубляться в вопрос о природе страданий и опустим подробные объяснения вопросов о сравнениях и численном оценивании страданий для индивидов и сообществ. Это темы для отдельных статей. Здесь мы лишь кратко приведем самое главное.

Страдания — это некоторая разновидность переживаний. Чаще всего имеются в виду все те переживания, которые обычно зовут "отрицательными": их примерами являются [боль](https://plato.stanford.edu/entries/pain/), печаль, страх, раздражение, тревога и злость. Но иногда в качестве страданий рассматриваются не все отрицательные переживания, а лишь какая-то наиболее проблематичная их часть.

Одни страдания могут быть хуже, чем другие. Самый простой (хотя и не единственный) способ выразить, что одни из них хуже других — это ввести числовые оценки _интенсивности_ страданий. Чем выше интенсивность страдания — тем оно хуже. Если целью является _лишь уменьшение страданий_, то переживания, не являющиеся страданиями, оцениваются нулевым значением.

Для принятия решений нам нужно не только оценивать отдельные переживания, но также и понимать, _сколько_ страданий переживалось тем или иным лицом с течением времени, а также целым сообществом лиц. Составление такой общей оценки на основе оценок отдельных моментов называется _[агрегацией](https://en.wikipedia.org/wiki/Aggregate_function)_, и наиболее известны три ее разновидности:
1. Cумма оценок всех мгновений;
2. Cредняя величина от оценок всех мгновений (т. е. сумма, поделенная на общее число мгновений);
3. Оценка наихудшего из всех мгновений.

Как правило, с понятием "[утилитаризма](https://reducingsuffering.github.io/337.html)" связывают лишь первые два вида агрегации, но наши дальнейшие рассуждения применимы и для прочих видов.

Важно отметить, что в жизни мы не имеем прямого доступа к переживаниям других персон, не уверены насчет того, кто вообще может страдать, не имеем общего стандарта для оценки переживаний и, как правило, редко пользуемся числами.

Однако это не мешает нам выносить интуитивные предположения о том, где и когда страданий больше, а где меньше — на основании ограниченных данных и вспомогательных предположений, вроде такого: похожие существа испытывают похожие переживания, если попадают в похожие обстоятельства и похожим образом реагируют на них.

<a name="2"></a>
## 2. Что значит "уменьшение"

Начнем с небольших простых примеров, когда люди могут считать, что чье-то страдание было уменьшено:
1. Человек принял обезболивающее, чтобы уменьшить свою головную боль;
2. Страдающий от какого-то психического заболевания сходил на сеанс психотерапии и на некоторое время почувствовал себя лучше, чем в предыдущие дни;
3. Один человек помог перейти дорогу другому человеку, испытывающему трудности.

Что объединяет все эти ситуации?

Кто-то совершает поступок, в результате которого то или иное страдание той или иной персоны прекращается. Возможно, ему на смену приходит другое страдание, но оно меньше по сравнению с тем, что было. Поэтому можно сказать, что страдания в результате поступка _уменьшились_ по сравнению с тем, что _испытывалось_ до этого.

Однако такое простое значение фразы "уменьшение страданий" крайне далеко от того, к чему призывает [консеквенциалистская](https://reducingsuffering.github.io/44.html) этика, такая как [негативный утилитаризм](https://reducingsuffering.github.io/what-is-negative-utilitarianism.html). В ней "уменьшение" сводится к тем или иным стратегиям "минимизации", и целью ставится **минимизация страданий** в глобальном масштабе, т. е. этика диктует добиваться того, чтобы во всем совокупном будущем — во все времена и во всех местах, доступных для влияния — _агрегированные страдания_ всех существ были _настолько малы, насколько этого возможно достигнуть_.

Перечислим основные отличия этой идеи от приведенных нами ранее примеров:

1\. Сравниваются не разные последовательные участки одной временной шкалы (типа вчерашнего дня и сегодняшнего), а _разные варианты_ того, что _могло бы произойти_ в будущем;<br>
2\. Последствия учитываются:<br>
2.1. Не только для какого-то одного человека или животного, а для всех _сентиентных_ (способных страдать) существ;<br>
2.2. Не на каком-то отдельном месте (вроде одной страны или одной планеты), а во _всех достижимых_ для нашего влияния местах;<br>
2.3. Не в какой-то ограниченной и краткой временной перспективе (типа дня или столетия), а для _всех будущих_ достижимых для нашего влияния времен;<br>
2.4. Не в рамках какого-то одного выбранного сценария будущего (где якобы "все пойдет по плану"), а _с учетом вариативности_.

Для полного объяснения этой идеи нам придется сначала изложить ряд вспомогательных соображений.

<a name="3"></a>
## 3. Локальный случай

Перед тем, как мы сможем доступно описать идею уменьшения страданий в _глобальном_ смысле, нам нужно рассмотреть задачи _локального_ (узкомасштабного) уменьшения страданий, поскольку они более просты в постановке и изучении. В дальнейшем мы объясним, что с ними не так и почему последовательный утилитаризм подразумевает нечто большее, чем просто локальную минимизацию страданий.

<a name="3.1"></a>
### 3.1. Субъективно оптимальный выбор

Представим себе, что есть некоторый вид схожих друг с другом и _ограниченных в пространстве и времени_ ситуаций (обстоятельств, положений дел), в которые могут попасть люди или иные _агенты_ (действующие лица).

Например, у вас заболела голова, или вы врач и принимаете пациента, или вы ведете машину и проезжаете перекресток, или вы размышляете о том, кому из своих знакомых пожертвовать тысячу рублей, или вы — водитель вагонетки в знаменитой [проблеме вагонетки](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D0%B1%D0%BB%D0%B5%D0%BC%D0%B0_%D0%B2%D0%B0%D0%B3%D0%BE%D0%BD%D0%B5%D1%82%D0%BA%D0%B8).

Итак, пусть мы выбрали какой-то конкретный вид схожих ситуаций. Можно представить, что в ситуациях такого вида разные агенты в принципе могли бы повести себя по разному. Например, разные врачи могут немного по разному вести прием пациентов — проявляя разный уровень вежливости, применяя разные медикаменты и приборы, и т. п. Более того, законы физики не запрещают врачу, например, начать плясать и петь во время приема. С другой стороны, агенты могут быть ограничены чем-то еще, если уменьшение страданий — не их единственная цель. Например, врач, как правило, имеет имеет цели не покалечить и не убить пациента (если только он не эвтаназиолог) в процессе приема.

Во всяком случае, нам нужно представить, что в рассматриваемой ситуации попавший в нее агент — главный герой нашей истории — теоретически мог бы вести себя более чем каким-то одним фиксированным способом. В частности, он может сознательно задумываться о выборе того, как ему поступить, рассматривая какие-то варианты A, B, C и т. д., и _предсказывая последствия_ для всех этих вариантов, _как если бы_ они произошли в реальности.

Возможно, что разные варианты поведения агента привели бы к разному количеству страданий у тех или иных участников ситуации. Например, от действий врача, очевидно, частично зависит то, какую боль будет испытывать на приеме пациент. От вашей реакции на головную боль зависит то, как долго она продлится. А от выбора, кому из ваших знакомых пожертвовать деньги, зависит то, что эти знакомые будут испытывать.

Итак, представляя разные варианты возможного развития событий и разные итоги этого развития — в виде количества страданий в течение какого-то времени у лиц, благополучие которых нас интересует — мы можем задаться вопросом о том, в каких случаях страданий _меньше_, а в каких — больше. Если агент, попавший в ситуацию, задается этим вопросом и пытается действовать так, чтобы страдание было _как можно меньшим_, можно сказать, что он пытается _минимизировать_ страдание в рамках ситуации или, что тоже самое, _уменьшить_ страдание (в рамках ситуации) _по сравнению_ с альтернативными путями развития событий.

Это означает, что агент решает определенную [задачу оптимизации](https://en.wikipedia.org/wiki/Mathematical_optimization), где целевая функция оценивает количество страданий, а целью является минимально возможное значение этой функции; возможно, с дополнительными ограничениями на множество допустимых решений. Важно отметить, что минимум не всегда нулевой — опции с нулевым значением может просто не быть среди возможных.

Но что, если я, рассматривая ситуацию, вижу одни варианты поведения агента и исходы, а другой человек — совсем другие? Что, если мы по разному предсказываем, что именно произойдет в результате того или иного выбора агента, имеем разное мнение о том, какие варианты выбора вообще нужно рассматривать, и, что хуже всего, по разному решили бы эту задачу, если бы находились на месте агента? Кто из нас прав? И что мы имеем в виду, говоря "_прав_"?

P. S. См. понятия _[контрфактуалов](https://bigenc.ru/c/kontrfaktual-noe-myshlenie-41076d)_ и _[возможных миров](https://knife.media/possible-worlds/)_ в философии для более полного и разностороннего погружения в идею "могло бы быть иначе".

<a name="3.2"></a>
### 3.2. Объективное качество выбора

Поскольку ситуации того или иного рассматриваемого нами вида могут происходить с совершенно разными агентами (возможно, даже неоднократно), и поведение этих агентов может отличаться, в принципе возможно сравнить их и заметить, что, в общем случае могут отличаться:
1. Набор рассматриваемых вариантов возможного поведения;
2. Принятое решение вести себя тем или иным образом;
3. Результаты (т. е. количество страданий);
4. Качество предсказаний (т. е. разница между тем, что они предсказывали, и что реально случилось в результате выбранного поведения).

Важно, что мы не должны ограничиваться рассмотрением лишь тех агентов, цели которых совпадают с минимизацией страданий. В подобные ситуации могут попадать агенты и с другими целями.

Итак, порой для оценки того, насколько _объективно_ хорошо тот или иной агент решает задачу, мы можем сравнивать его с другими агентами в похожих ситуациях и оценивать, насколько малого числа страданий по сравнению с другими ему удалось добиться. Например, врач, занимающийся обезболиванием, может обратиться к опыту своих коллег или к соответствующей литературе со статистикой.

Но что делать, если никаких данных о других агентах в схожих ситуациях нет? Например, если никто никогда еще не оказывался в подобной ситуации? Приведем пару соображений на этот счет.

Во-первых, если задачу можно разбить на подзадачи, качество решений которых (данным агентом) поддается оценке, то и качество решения большой задачи можно оценить через качество решения ее подзадач, т. к. оно от них прямо зависит.

Во-вторых, поскольку качество решения задачи зависит от качества предсказаний, а качество предсказаний зависит от того, насколько хорошей моделью реальности обладает агент, мы можем сфокусироваться на оценке качества модели реальности этого агента в целом или тех ее частей, которые кажутся наиболее релевантными для рассматриваемой задачи.

Например, если задача, по-видимому, требует владения биоинформатикой, мы можем предположить, что агент, который (насколько нам известно) хорошо разбирается в биоинформатике, решит ее лучше того, кто плохо в ней разбирается.

P. S. Для углубления в тему см. дискуссии об [объективном консеквенциализме против субъективного](https://philpapers.org/browse/objective-and-subjective-consequentialism) и [максимизирующем против удовлетворяющего](https://philpapers.org/browse/maximizing-and-satisficing-consequentialism).

<a name="3.3"></a>
### 3.3. Вероятности наступления событий

Мы не всегда можем с хорошей вероятностью предсказывать последствия нашего выбора. И даже когда у нас это получается, у нас нет детальных карт переживаний существ, благополучие которых нас интересует. В частности, мы можем вообще сомневаться в том, что они сентиентны, в то же время не имея полной уверенности и в обратном.

Однако, для принятия решений нам необязательно детально предсказывать будущее. Мы можем рассматривать два или больше варианта того, что произойдет в результате того или иного нашего выбора. Как же в таких случаях сравнивать разные варианты выбора, чтобы хорошо решать поставленную задачу?

Условия, при которых мы предполагаем более одного возможного исхода у одного и того же выбора, называются _условиями риска_, если мы, по крайней мере, имеем те или иные  _субъективные вероятности_ (степени уверенности) наступления каждого из исходов. И называются _условиями неопределенности_, если таких вероятностей у нас нет, или, что еще хуже — нет идей, что вообще может произойти.

Разработано множество _[теорий принятия решений](https://www.lesswrong.com/posts/zEWJBFFMvQ835nq6h/decision-theory-faq)_, чтобы объяснить, как нам лучше поступать в различных ситуациях, чтобы добиваться той или иной цели. 

Что делать, если мы находимся в условиях неопределенности? Для некоторых видов таких задач могут существовать специфические для них приемы, которые обычно хорошо работают. Но в общем случае лучше перейти к условиям риска, попытавшись определить наиболее правдоподобные варианты последствий для каждого из вариантов выбора и оценить вероятности наступления этих последствий.

В контексте условий риска рассмотрим один, наиболее известный принцип — _[максимизацию ожидаемой полезности/ценности](https://www.cold-takes.com/expected-value/)_, обоснованный в [работе](https://reducingsuffering.github.io/347.html) фон Неймана и Моргенштерна.

Пусть мы должны сделать выбор между вариантами A и B, где у варианта A возможны исходы, имеющие ценность (полезность) a<sub>1</sub>, a<sub>2</sub>, ..., a<sub>n</sub> с вероятностями p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>n</sub> соответственно, а у варианта B — исходы, имеющие ценность b<sub>1</sub>, b<sub>2</sub>, ..., b<sub>m</sub> с вероятностями q<sub>1</sub>, q<sub>2</sub>, ..., q<sub>m</sub> соответственно. Тогда мы составляем оценки _ожидаемой ценности (полезности)_ f для вариантов A и B по формулам f(A) = p<sub>1</sub>a<sub>1</sub> + p<sub>2</sub>a<sub>2</sub> + ... + p<sub>n</sub>a<sub>n</sub> и f(B) = q<sub>1</sub>b<sub>1</sub> + q<sub>2</sub>b<sub>2</sub> + ... + q<sub>m</sub>b<sub>m</sub> соответственно. Согласно принципу, лучшим из этих решений будет то, у которого максимальная ожидаемая ценность f. В случае большего числа вариантов выбора все аналогично — нужно будет оценить ожидаемую ценность f(X) для каждого варианта X и выбрать вариант с наибольшей из них.

Поскольку в качестве цели мы рассматриваем уменьшение страданий, ценность того или иного исхода будет равна количеству страданий, взятому с отрицательным знаком. Таким образом, максимизация ожидаемой ценности будет превращаться в _минимизацию ожидаемых страданий_.

По какой причине рекомендованы именно такие формулы?

Есть две основные группы причин. Во-первых, [можно показать](https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem), что такой ход мышления будет наименее противоречив с точки зрения некоторых довольно убедительных предпосылок. Во-вторых, [можно убедиться](https://reducing-suffering.org/why-maximize-expected-value/) путем сбора статистики на практике или путем статистического моделирования, что при многократном принятии решений в ситуациях с соответствующими распределениями вероятностей и исходами, именно формула ожидаемой ценности будет оптимальна среди [функций](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_(%D0%BC%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0)) от вероятностей и ценностей исходов.

В жизни мы не всегда имеем возможность производить подобные расчеты в явном виде, но можем позаботиться о том, чтобы наши более грубые, интуитивные методы принятия решений приближались к этому идеалу. Например, при оценке некоторого плана действий, мы должны учитывать не только то, с какой вероятностью что-то может пойти не так, но и то, каковы будут последствия нашей неудачи (поскольку в формуле вероятность _умножается_ на ценность исхода). Даже крайне маловероятные последствия возможной неудачи, если они достаточно масштабны, могут сделать план неоправданным.

Важно отметить, что принцип максимизации ожидаемой ценности не идеален. Порой вместо него или в дополнение к нему есть смысл обращаться к другим приемам из [теории игр](https://reducingsuffering.github.io/245.html) и иных [теорий принятия решений](https://casparoesterheld.com/a-comprehensive-list-of-decision-theories/). В частности, у описанного принципа возникают проблемы в случаях, когда [другие агенты могут предсказывать ваш выбор еще до того, как вы его сделаете](https://lesswrong.ru/w/%D0%9F%D0%B0%D1%80%D0%B0%D0%B4%D0%BE%D0%BA%D1%81_%D0%9D%D1%8C%D1%8E%D0%BA%D0%BE%D0%BC%D0%B0_%D1%81%D0%BE%D0%B6%D0%B0%D0%BB%D0%B5%D1%8F_%D0%BE_%D1%81%D0%B2%D0%BE%D0%B5%D0%B9_%D1%80%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D0%B8), и в ситуациях [коллективного принятия решений](https://www.jstor.org/stable/20010532), подобных голосованию на выборах.

<a name="3.4"></a>
### 3.4. Время на принятие решений

До сих пор мы говорили о задачах оптимизации упрощенно, как если бы все сводилось лишь к тому, чтобы выбрать лучший из вариантов, набор которых уже известен. Однако, если ситуация не требует от нас мгновенной реакции, то реальная задача, которую мы решаем, выглядит несколько сложнее. Ведь как сам набор вариантов дальнейшего поведения, так и оценки того, насколько хороши те или иные варианты, могут меняться в процессе наших размышлений (если мы узнаем что-то новое) или просто пассивного ожидания (если внешние обстоятельства меняются).

Например, мы можем иметь задачу вида "за 10 минут найти наилучшую стратегию поведения для следующих 20 минут, и придерживаться ее". Изначально мы можем даже не иметь никаких вариантов кроме "подумать еще" и "ничего не делать / ждать". А в процессе обдумывания перед нами может стоять выбор между "подумать над расширением числа вариантов стратегий", "уточнить оценку последствий для стратегии A, B или C", "перейти к ожиданию" или "закончить размышления, выбрав стратегию, которая оптимальна при текущих оценках".

Мы не будем углубляться в подробности и лишь упомянем, что в подобных задачах пригождаются такие величины как [ценность опций](https://forum.effectivealtruism.org/topics/option-value) (ценность наличия выбора, пока не сделано что-то, чего уже не обратить вспять) и [ценность информации](https://forum.effectivealtruism.org/posts/8w2hNT5WtDMzoaGuy/when-to-find-more-information-a-short-explanation) (то, насколько сильно новая информация может повлиять на оценки вариантов — и в результате на выбор). Подобные вопросы рассматриваются также в теме [ограниченной рациональности](https://plato.stanford.edu/entries/bounded-rationality/).

<a name="4"></a>
## 4. Горизонт планирования

До сих пор, рассуждая об уменьшении страданий в тех или иных ситуациях, мы не поднимали вопроса о том, в каком именно масштабе нам лучше было бы производить агрегацию для оценки уровня страданий.

Какими вообще могут быть масштабы агрегации?

Мы можем оценивать последствия наших действий в краткосрочной или долгосрочной перспективе, от минут до вечности. Мы можем оценивать их только для тех, кто уже существует, или также для тех, кто еще не появился на свет. Мы можем оценивать их для одного человека или для нескольких, или для сообщества людей, или для всего человечества. Мы можем оценивать их для других животных или обитателей иных планет.

Так или иначе, речь идет о разных участках пространства-времени, в которых обитают или будут обитать те, чье благополучие нас интересует.

Что, если перед тем, как выбирать поступок, нам нужно выбрать, на каком участке действительности вообще рассматривать последствия нашего поступка? Зачем вообще задаваться таким вопросом? Что может быть плохого в том, что мы уменьшаем страдания в каком-то одном выбранном нами участке пространственно-временной действительности?

Проблема в том, что уменьшая их в одном участке, мы можем одновременно увеличивать их в каком-то другом. Более того, в некотором смысле мы _почти всегда_ [именно это и делаем](https://kkirdan.github.io/blog/a2.html).

Чтобы понять, почему это так, рассмотрим для начала случай, когда мы решаем, пустить ли единицу нашего ресурса на уменьшение страданий в одном участке действительности A, или же в другом участке B, отличном от него. Предположим, что наш выбор имеет разные последствия для этих участков. Тогда если мы вкладываем в A, мы при этом _упускаем_ возможность вложить ресурс в B. Это и означает, что выбрав вложиться в A, мы _увеличили_ страдания в B по сравнению с той альтернативой, в которой мы вложили бы весь ресурс в B. 

Так, если мы делаем пожертвование на борьбу с бедностью в городе X (в перспективе ближайших N лет), мы упускаем возможность пожертвовать эти же деньги на уменьшение страданий подневольных животных в стране Y (в перспективе ближайших M лет). И наоборот — жертвуя на помощь животным, мы упускаем возможность помочь людям.

Конечно, мы можем рассматривать два участка действительности вместе, как один участок, и задуматься над тем, как уменьшить агрегированные страдания на всем этом участке. Разумеется, это не значит, что мы перестанем увеличивать страдания на обоих этих участках _по отдельности_ по сравнению со сценариями, где мы отдали какому-то одному из них все свои ресурсы. Однако, мы будем уменьшать их _в целом_ на более крупном участке действительности и, по крайней мере, это будет менее морально предвзятым решением.

Например, мы можем измерить эффект от каждого дополнительно вкладываемого доллара для двух разных организаций и распределить свои средства между ними так, чтобы суммарный эффект был наибольшим (в самом простом случае может оказаться, что лучше вложить все средства в ту из этих организаций, эффективность которой выше).

Однако, проблема локальности наших действий никуда не делась. Да, в конкретной ситуации выбора мы решили объединить разные участки действительности в один, чтобы оценить агрегированный эффект от наших действий на этом большем участке. Но мы все еще игнорируем те участки действительности, которые _просто не рассматривались_ в ситуации выбора изначально.

Выбирая лишь между помощью одному человеку или другому, мы игнорируем всех прочих людей, которым можно было бы помочь. Выбирая между помощью слепым и помощью людям на предсмертном одре, мы игнорируем людей с иными проблемами и в иных обстоятельствах. Выбирая между помощью подневольным животным или людям, мы игнорируем диких животных, а также тех существ искусственного происхождения, которые могут прийти на смену людям в будущем.

При этом мы _не можем_ гарантированно избежать того или иного влияния на другие участки пространства-времени помимо тех, что у нас под носом. Все в мире взаимосвязано и последствия наших действий могут распространяться очень далеко в пространстве и времени. Более того, наличие в мире множества [хаотических систем](https://journals.sagepub.com/doi/10.1177/001872679304600701) означает, что последствия некоторых действий могут быть крайне масштабными, но при этом почти непредсказуемыми.

Получается, что если мы будем необоснованно ограничивать свой горизонт планирования теми или иными локальными участками пространства-времени, мы рискуем нарушить один из базовых принципов утилитарной этики —  _принцип равного рассмотрения интересов_ (также известный как _[принцип непредвзятости](https://utilitarianism.net/types-of-utilitarianism/)_).

Поэтому встает справедливый вопрос: можно ли каким-то образом принимать решения так, чтобы они были оптимальны не для каких-то узких участков действительности, а для всего доступного для нашего влияния пространства-времени?

<a name="5"></a>
## 5. Глобальный случай

Что будет, если наш горизонт планирования станет неограниченным? Или, если это невозможно, какой выбор горизонта планирования наиболее обоснован с точки зрения принципа равного рассмотрения интересов?

<a name="5.1"></a>
### 5.1. Постановка задачи

Предположим, что мы рассматриваем два варианта поведения, A и B, пошагово увеличивая горизонт планирования как в пространстве, так и во времени. Например, сначала мы спросим, что уменьшает страдания в масштабе одного дня и одного человеческого поселения, затем — в масштабе одного года и одной страны, и т. д., с каждым шагом захватывая все больше и больше от пространства-времени для своего планирования.

Сойдется ли такой процесс размышлений к какой-либо одной из стратегий A или B?

Заметим, речи не идет о том, чтобы с каждым шагом увеличивались еще и наши знания о вселенной. Нет, сейчас мы хотим понять, можно ли при _ограниченном объеме знаний_ и _ограниченном объеме ресурсов_ в принципе корректно поставить вопрос о глобальном уменьшении страданий во вселенной.

При некоторых начальных предположениях — да. По крайней мере, если мы полагаем объем и временную протяженность потенциально обитаемой части вселенной ограниченными, то начиная с какого-то шага ответ перестанет меняться.

Однако, если мы предполагаем, что вселенная в том или ином отношении бесконечна (в пространственных измерениях или во времени), и общее число сентиентных существ в ней тоже может оказаться бесконечным, то у нас возникают [серьезные затруднения](https://nickbostrom.com/ethics/infinite.pdf) при попытке оценить страдания. Так, если в качестве метода агрегации мы используем суммирование, то все оценки ожидаемых страданий будут стремиться к бесконечности, и мы не сможем ими пользоваться. В этом случае, как минимум, требуется доработка способов оценки страданий, и на этом пути нам [придется пожертвовать](https://askell.io/files/Askell-PhD-Thesis.pdf) какими-то из наших исходных моральных интуиций.

С другой стороны, мы можем предположить, что даже если вселенная бесконечна, _сфера нашего потенциального влияния_ конечна. Так, согласно теории относительности нельзя двигаться быстрее скорости света, и это накладывает некоторые ограничения на то, [какую часть вселенной](https://ru.wikipedia.org/wiki/%D0%A1%D0%B2%D0%B5%D1%82%D0%BE%D0%B2%D0%BE%D0%B9_%D0%BA%D0%BE%D0%BD%D1%83%D1%81) мы способны затронуть. Кроме того, сфера нашего влияния на будущее может быть физически ограничена событиями вроде [тепловой смерти](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BF%D0%BB%D0%BE%D0%B2%D0%B0%D1%8F_%D1%81%D0%BC%D0%B5%D1%80%D1%82%D1%8C_%D0%92%D1%81%D0%B5%D0%BB%D0%B5%D0%BD%D0%BD%D0%BE%D0%B9) вселенной или [большого разрыва](https://ru.wikipedia.org/wiki/%D0%91%D0%BE%D0%BB%D1%8C%D1%88%D0%BE%D0%B9_%D1%80%D0%B0%D0%B7%D1%80%D1%8B%D0%B2). В таких случаях можно было бы просто отбросить из наших расчетов все, на что невозможно повлиять.

Впрочем, здесь возможна неожиданная проблема. Представим себе, что где-то за пределами нашей зоны влияния есть агент, столь интеллектуально похожий на вас, что ваши с ним решения и сами методы принятия решений в похожих ситуациях коррелируют, какими бы они ни были (при этом у него вовсе не обязательно такая же цель оптимизации, как у вас). Следует ли считать, что во всех ситуациях, в которых ваши решения коррелируют, последствия действий таких похожих на вас агентов — являются также и _последствиями ваших собственных действий_? И если они тоже осознали это, можете ли вы все вместе [сделать что-то](https://longtermrisk.org/multiverse-wide-cooperation-via-correlated-decision-making/), что увеличит взаимную выгоду от принимаемых вами решений?

В конце концов, мы [можем усомниться](https://reducing-suffering.org/believe-infinity/) в том, что бесконечности вообще реальны. Но к сожалению, если мы допускаем хотя бы ненулевую вероятность того, что ошибаемся в этом, и что способны повлиять на бесконечные масштабы, перед нами снова будет вставать обозначенная проблема. В итоге получится, что мы находимся в положении, похожем на знаменитое [пари Паскаля](https://ru.wikipedia.org/wiki/%D0%9F%D0%B0%D1%80%D0%B8_%D0%9F%D0%B0%D1%81%D0%BA%D0%B0%D0%BB%D1%8F). Должны ли мы _ставить всё_ на вариант, предполагающий бесконечность нашего влияния?

В любом случае, как для уточнения формулировки самой задачи глобального уменьшения страданий с учетом наших наиболее важных интуиций, так и для ее решения, нам нужно систематически работать над улучшением своих _[методов познания](https://ru.wikipedia.org/wiki/%D0%AD%D0%BF%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%8F)_ и _[моделей реальности](https://lesswrong.ru/%D0%9A%D0%B0%D1%80%D1%82%D0%B0_%D0%B8_%D1%82%D0%B5%D1%80%D1%80%D0%B8%D1%82%D0%BE%D1%80%D0%B8%D1%8F)_, чтобы _повысить шансы_ на то, что мы движемся в верном направлении (при условии что такое направление вообще существует).

<a name="5.2"></a>
### 5.2. Решение задачи

Итак, предположим, что та или иная постановка задачи глобального уменьшения страданий — подразумевает ли она только конечную зону ответственности, или бесконечную, или какую-то их комбинацию — корректна. Как нам ее решать?

По-видимому, если мы не имеем никакой информации о тех или иных участках пространства-времени (например, об иных планетах или о будущих тысячелетиях), можно [исключать](https://www.pure.ed.ac.uk/ws/portalfiles/portal/11822126/Consequentialism_and_the_Principle_of_Indifference.pdf) их из расчетов, т. к. они все равно давали бы одинаковый вклад в цифры для оценок всех вариантов действий. Однако, если у нас есть хоть какие-то догадки, склоняющие чашу весов в ту или иную сторону, нам, в идеале, следует их учитывать.

<span class="draft">...</span>

Поскольку идея уменьшения страданий основана на отрицательности (негативности) определенного класса явлений (страданий), может сложиться впечатление, будто ее реализация сводится к расчетам о том, как _чего-то избежать_. Помимо этого, может казаться, что уменьшение страданий в глобальном масштабе можно свести к отдельным актам уменьшения страданий в локальных, малых масштабах. Однако, и то, и другое неверно.

Оптимизация в сколько-нибудь крупном масштабе требует сложной системы _[инструментальных ценностей](https://streetepistemology.ru/instrumentalnie-i-terminalnie-tsennosti)_, подразумевающей как необходимость накопления чего-либо (а значит, решения задач максимизации, а не минимизации), так и необходимость соблюдения ограничений на способы оптимизации, используемые в решении локальных задач, даже если они подразумевают минимизацию страданий.

Самым простым примером может служить [тезис](https://en.wikipedia.org/wiki/Instrumental_convergence) об _инструментальной конвергенции_ (верный как для людей, так и для искусственных агентов) — для уменьшения страданий, как и почти для _любых иных целей_, важно самосохранение (очевидно, вы больше не можете уменьшать чужое страдание, если уже мертвы), сохранение целостности цели (сопротивление изменению главной цели на что-то другое — например, избегание употребления веществ, несущих существенный риск усилить ваши эгоистические тенденции), самосовершенствование (включая развитие своих приемов мышления, улучшение привычек и заботу о здоровье) и накопление рычагов влияния на мир (например, материальных ресурсов, информации, [репутации и социального капитала](https://www.centreforeffectivealtruism.org/blog/considering-considerateness-why-communities-of-do-gooders-should-be)).

Помимо этого, рядом авторов отмечается важность полноценной [насыщенной](https://reducingsuffering.github.io/magnus-vinding-suffering-focused-ethics-and-the-importance-of-happiness.html) жизни, [кооперативного настроя](https://centerforreducingsuffering.org/research/why-altruists-should-be-cooperative/) в отношении людей с другими ценностями ([даже](https://longtermrisk.org/reasons-to-be-nice-to-other-value-systems/) если им неинтересно уменьшение страданий), [уважения чужих прав](https://lesswrong.ru/w/%D0%9E_%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%B5_%D0%BB%D1%8E%D0%B1%D0%B5%D0%B7%D0%BD%D0%BE%D1%81%D1%82%D0%B8_%D0%BE%D0%B1%D1%89%D0%B8%D0%BD_%D0%B8_%D1%86%D0%B8%D0%B2%D0%B8%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8), [миролюбия и ненасилия](https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism). 

<span class="draft">Не дописано!

Здесь нужен пример кооперации.

Еще было бы неплохо описать ITN.</span>

https://reducingsuffering.github.io/450.html

<a name="6"></a>
## 6. Модификации
<a name="6.1"></a>
### 6.1. Дополнительные цели оптимизации

Рассмотрим случай, когда помимо уменьшения страданий агент имеет другие цели, также сводимые к уменьшению или увеличению количества чего-либо во вселенной. Например, агент может ценить увеличение своего счастья, или количества удовольствий во вселенной, или продолжительности жизни людей, или уменьшения числа нарушений автономии одних агентов другими, или уменьшения числа смертей.

В _общем случае_ выглядит маловероятным, чтобы решение задачи оптимизации одной ценности было полностью совместимо с решением задачи оптимизации какой-то другой. Подобно конфликту между оптимизацией одной и той же ценности для разных существ или в разных пространственно-временных масштабах, у нас также рано или поздно может вскрыться конфликт между оптимизацией разных ценностей на одних и тех же участках действительности, в том числе и в глобальном масштабе.

Поэтому рано или поздно (например, когда вы будете думать о том, в какую организацию пожертвовать свободные деньги, или на какие темы почитать статьи и пересказать своим друзьям) может встать вопрос о том, в какой степени для вас важны эти прочие вещи по сравнению со страданиями.

Один из способов совместить разные цели оптимизации — ввести что-то вроде курса обмена одних ценностей на другие. Т. е. нужно понять, сколько примерно страданий, по-вашему, эквивалентны тому или иному количеству другой отрицательной ценности (например, одной человеческой смерти) или сколько страданий можно окупить тем или иным количеством положительной ценности (например, удовольствиями). Если же страдания (или какая-то их разновидность) для вас всегда важнее (как в системах ценностей [с лексическим порядком](https://casparoesterheld.com/2016/08/08/lexicographic-utility-functions/)), то другие ценности просто не должны играть (неинструментальной) роли в принятии масштабных решений, пока во вселенной могут существовать страдания.

С другой стороны, _частичная_ совместимость разных человеческих ценностей не только достижима, но и неизбежна. В частности, очевидно, что вы просто не сможете быть успешными в уменьшении чьих-либо страданий, если не будете прибегать к компромиссам с эгоистической стороной своего существа и как-то заботиться _о себе лично_ — избегая сильных страданий и поощряя себя удовольствием за проделанную работу.

Кроме того, в сфере науки, философии и технологии есть множество направлений, в которых заинтересованы носители самых разных ценностей. Некоторые из этих направлений могут быть более значимыми для уменьшения страданий и каких-то дополнительных целей, чем другие. Возможным примером может служить [работа](https://longtermrisk.org/research-agenda) по уменьшению рисков глобальных конфликтов, связанных с искусственным интеллектом.

<a name="6.2"></a>
### 6.2. Ограничения на способы оптимизации

Рассмотрим теперь случай, когда дополнительной целью агента является соблюдение ограничений _[деонтологического](https://plato.stanford.edu/entries/ethics-deontological/)_ характера на то, что именно он может делать в процессе оптимизации.

Хотя и в этом случае ясно, что теоретически они могут конфликтовать с уменьшением страданий, в части случаев накал конфликта может оказаться намного меньшим, чем если бы вы, например, преследовали дополнительную цель максимизации удовольствий во вселенной.

Так, если вы придерживаетесь деонтологии, состоящей из запрета на поедание мяса животных, но знаете, как при этом избежать отрицательных последствий для вашего здоровья из-за отсутствия мяса в вашем рационе, это вряд ли будет угрожать вашей деятельности, направленной на уменьшение страданий. Более того, возможно, что избегая поедания мяса животных, вы [способствуете](https://reducing-suffering.org/does-vegetarianism-make-a-difference/) уменьшению страданий даже больше, чем если бы вы были мясоедом. Проблема, однако, может возникнуть, если в результате неудачного стечения обстоятельств вы окажетесь в местах, где можно выжить и остаться здоровым только употребляя мясо.

С другой стороны, наличие у агента деонтологии может сопровождаться явным желанием увеличить число ее сторонников в мире. Таким образом, может сформироваться дополнительная цель оптимизации и тоже возможен конфликт.

<a name="6.3"></a>
### 6.3. Ограничения морального круга

[Моральный круг](https://reducingsuffering.github.io/376.html) — это круг существ, благополучие которых нас в конечном счете интересует, когда мы принимаем моральные решения.

В гедонистическом утилитаризме моральный круг охватывает всех сентиентных существ. Кроме того, фундаментальный для утилитаризма _[принцип беспристрастности](https://utilitarianism.net/types-of-utilitarianism/)_ (он же — _принцип равного рассмотрения интересов_) подразумевает, что одинаковые страдания разных персон должны давать один и тот же вклад в общие оценки страданий.

Однако существует множество взглядов, которые пересекаются с утилитаризмом в тех или иных аспектах, но отвергают принцип беспристрастности или сужают моральный круг.

Так, довольно известная в философии морали точка зрения, относимая к [person-affecting views](https://en.wikipedia.org/wiki/Person-affecting_view), подразумевает, что мы должны заботиться лишь о тех, кто уже существует, исключая из морального круга тех, кто еще не появился на свет.

Помимо этого встречаются позиции, ограничивающие моральный круг человеческим видом или даже одной нацией или племенем.

Крайняя форма сужения морального круга — это моральный эгоизм, согласно которому нашей обязанностью является лишь забота о нашем собственном благополучии.

Помимо этого встречаются позиции, которые вместо явного сужения морального круга отвергают принцип беспристрастности.

Например, не отказываясь от оценки благополучия будущих, еще не появившихся на свет персон, некоторые теории предлагают [дисконтировать](https://en.wikipedia.org/wiki/Social_discount_rate) это благополучие, т. е. считать его значимость тем меньшей, чем сильнее отдалены во времени эти персоны.

<a name="sources"></a>
## Источники

* Стэнфордская энциклопедия философии, [Консеквенциализм](https://reducingsuffering.github.io/44.html)
* К. Кирдан, [Что такое негативный утилитаризм](https://reducingsuffering.github.io/what-is-negative-utilitarianism.html) (2020)
* Centre for Effective Altruism, [Введение в эффективный альтруизм](https://reducingsuffering.github.io/78.html)
* Stanford Encyclopedia of Philosophy, [Pain](https://plato.stanford.edu/entries/pain/)
* Wikipedia, [Aggregate function](https://en.wikipedia.org/wiki/Aggregate_function)
* Электронная философская энциклопедия, [Утилитаризм](https://reducingsuffering.github.io/337.html)
* Википедия, [Проблема вагонетки](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D0%B1%D0%BB%D0%B5%D0%BC%D0%B0_%D0%B2%D0%B0%D0%B3%D0%BE%D0%BD%D0%B5%D1%82%D0%BA%D0%B8)
* Wikipedia, [Mathematical optimization](https://en.wikipedia.org/wiki/Mathematical_optimization)
* Большая российская энциклопедия, [Контрфактуальное мышление](https://bigenc.ru/c/kontrfaktual-noe-myshlenie-41076d)
* Агата Коровина, [«Реальный мир — это тот, где ты жив, а возможный — где ты мертв». Как философы путешествуют по возможным мирам](https://knife.media/possible-worlds/)
* Douglas W. Portmore, [Objective and Subjective Consequentialism](https://philpapers.org/browse/objective-and-subjective-consequentialism)
* Douglas W. Portmore, [Maximizing and Satisficing Consequentialism](https://philpapers.org/browse/maximizing-and-satisficing-consequentialism)
* Luke Muehlhauser, [Decision Theory FAQ](https://www.lesswrong.com/posts/zEWJBFFMvQ835nq6h/decision-theory-faq) (2013)
* Caspar Oesterheld, [A comprehensive list of decision theories](https://casparoesterheld.com/a-comprehensive-list-of-decision-theories/)
* Brian Tomasik, [Why Maximize Expected Value?](https://reducing-suffering.org/why-maximize-expected-value/) (2007-2016)
* Holden Karnofsky, [Expected value](https://www.cold-takes.com/expected-value/)
* Wikipedia, [Von Neumann–Morgenstern utility theorem](https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem)
* Википедия, [Функция (математика)](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_(%D0%BC%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0))
* Джон фон Нейман, Оскар Моргенштерн, [Теория игр и экономическое поведение](https://reducingsuffering.github.io/347.html) (1970)
* Стэнфордская энциклопедия философии, [Теория игр](https://brickofknowledge.com/articles/game-theory)
* Элиезер Юдковский, [Парадокс Ньюкома: сожалея о своей рациональности](https://lesswrong.ru/w/%D0%9F%D0%B0%D1%80%D0%B0%D0%B4%D0%BE%D0%BA%D1%81_%D0%9D%D1%8C%D1%8E%D0%BA%D0%BE%D0%BC%D0%B0_%D1%81%D0%BE%D0%B6%D0%B0%D0%BB%D0%B5%D1%8F_%D0%BE_%D1%81%D0%B2%D0%BE%D0%B5%D0%B9_%D1%80%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D0%B8) (2015)
* John C. Harsanyi, [Rule Utilitarianism and Decision Theory](https://www.jstor.org/stable/20010532) (1975)
* Centre for Effective Altruism, [Option value](https://forum.effectivealtruism.org/topics/option-value)
* David Manheim, [When To Find More Information: A Short Explanation](https://forum.effectivealtruism.org/posts/8w2hNT5WtDMzoaGuy/when-to-find-more-information-a-short-explanation) (2019)
* Stanford Encyclopedia of Philosophy, [Bounded Rationality](https://plato.stanford.edu/entries/bounded-rationality/) (2018)
* К. Кирдан, [Плюс в одном месте — это минус в другом](https://kkirdan.github.io/blog/a2.html) (2023)
* Hal Gregersen, Lee Sailer, [Chaos Theory and Its Implications for Social Science Research](https://journals.sagepub.com/doi/10.1177/001872679304600701) (1993)
* Centre for Effective Altruism, [Naive vs. sophisticated consequentialism](https://forum.effectivealtruism.org/topics/naive-vs-sophisticated-consequentialism)
* Nick Bostrom, [Infinite Ethics](https://nickbostrom.com/ethics/infinite.pdf) (2003-2011)
* Amanda Askell, [Pareto Principles in Infinite Ethics](https://askell.io/files/Askell-PhD-Thesis.pdf) (2018)
* Brian Tomasik, [Should We Believe in Infinity?](https://reducing-suffering.org/believe-infinity/) (2014-2018)
* Elinor Mason, [Consequentialism and the Principle of Indifference](https://www.pure.ed.ac.uk/ws/portalfiles/portal/11822126/Consequentialism_and_the_Principle_of_Indifference.pdf) (2004)
* Википедия, [Световой конус](https://ru.wikipedia.org/wiki/%D0%A1%D0%B2%D0%B5%D1%82%D0%BE%D0%B2%D0%BE%D0%B9_%D0%BA%D0%BE%D0%BD%D1%83%D1%81)
* Википедия, [Тепловая смерть Вселенной](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BF%D0%BB%D0%BE%D0%B2%D0%B0%D1%8F_%D1%81%D0%BC%D0%B5%D1%80%D1%82%D1%8C_%D0%92%D1%81%D0%B5%D0%BB%D0%B5%D0%BD%D0%BD%D0%BE%D0%B9) 
* Википедия, [Большой разрыв](https://ru.wikipedia.org/wiki/%D0%91%D0%BE%D0%BB%D1%8C%D1%88%D0%BE%D0%B9_%D1%80%D0%B0%D0%B7%D1%80%D1%8B%D0%B2)
* Caspar Oesterheld, [Multiverse-wide Cooperation via Correlated Decision Making](https://longtermrisk.org/multiverse-wide-cooperation-via-correlated-decision-making/) (2017)
* Википедия, [Эпистемология](https://ru.wikipedia.org/wiki/%D0%AD%D0%BF%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%8F)
* Элиезер Юдковский, [Рациональность: от ИИ до зомби](https://lesswrong.ru/w/%D0%A0%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D1%8C_%D0%BE%D1%82_%D0%98%D0%98_%D0%B4%D0%BE_%D0%97%D0%BE%D0%BC%D0%B1%D0%B8) (2015)
* Уличная эпистемология, [Инструментальные и терминальные ценности. Как понять, что действительно важно для собеседника](https://streetepistemology.ru/instrumentalnie-i-terminalnie-tsennosti)
* Wikipedia, [Instrumental convergence](https://en.wikipedia.org/wiki/Instrumental_convergence)
* Stefan Schubert, [Considering Considerateness: Why communities of do-gooders should be exceptionally considerate](https://forum.effectivealtruism.org/posts/Cn3dAZhtqeBXYmQvF/considering-considerateness-why-communities-of-do-gooders) (2017)
* Магнус Виндинг, [Этика противодействия страданию и важность счастья](https://reducingsuffering.github.io/magnus-vinding-suffering-focused-ethics-and-the-importance-of-happiness.html) (2021)
* Magnus Vinding, [Why altruists should be cooperative](https://centerforreducingsuffering.org/research/why-altruists-should-be-cooperative/) (2020)
* Teo Ajantaival, [Peacefulness, nonviolence, and experientialist minimalism](https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism) (2022)
* Скотт Александер, [О пользе любезности, общин и цивилизации](https://lesswrong.ru/w/%D0%9E_%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%B5_%D0%BB%D1%8E%D0%B1%D0%B5%D0%B7%D0%BD%D0%BE%D1%81%D1%82%D0%B8_%D0%BE%D0%B1%D1%89%D0%B8%D0%BD_%D0%B8_%D1%86%D0%B8%D0%B2%D0%B8%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8) (2014)
* Brian Tomasik, [Reasons to Be Nice to Other Value Systems](https://longtermrisk.org/reasons-to-be-nice-to-other-value-systems/) (2015)
* Брайан Томасик, [Почему мы должны оставаться кооперативными](https://reducingsuffering.github.io/450.html) (2011-2019)
* Jesse Clifton, [Cooperation, Conflict, and Transformative Artificial Intelligence: A Research Agenda](https://longtermrisk.org/research-agenda) (2020)
* Caspar Oesterheld, [Lexicographic utility functions](https://casparoesterheld.com/2016/08/08/lexicographic-utility-functions/) (2016)
* Stanford Encyclopedia of Philosophy, [Deontological Ethics](https://plato.stanford.edu/entries/ethics-deontological/)
* Brian Tomasik, [Does Vegetarianism Make a Difference?](https://reducing-suffering.org/does-vegetarianism-make-a-difference/) (2006-2014)
* Сигаль Сэмюэл, [Звери, роботы и люди: есть ли шансы на равноправие?](https://newochem.io/moral-circle/) (2019)
* MacAskill W., Meissner D., Chappell R. Y., [Elements and Types of Utilitarianism](https://utilitarianism.net/types-of-utilitarianism/) (2023)
* Wikipedia, [Person-affecting view](https://en.wikipedia.org/wiki/Person-affecting_view)
* Wikipedia, [Social discount rate](https://en.wikipedia.org/wiki/Social_discount_rate)

<a name="further"></a>
## Что еще почитать

* К. Кирдан, [Что такое этика](https://reducingsuffering.github.io/what-is-ethics.html) (2021)
* Евгений Кононов, [Аналитическая метафизика. Тематический обзор](https://reducingsuffering.github.io/539.html) (2023)
* Benjamin Todd, [Counterfactuals and how they change our view of what does good](https://80000hours.org/articles/counterfactuals/) (2021)
* Centre for Effective Altruism, [Model uncertainty](https://forum.effectivealtruism.org/topics/model-uncertainty)
* Centre for Effective Altruism, [Crucial consideration](https://forum.effectivealtruism.org/topics/crucial-consideration)
* Lukas Gloor, [Expected Utility](https://crucialconsiderations.org/rationality/expected-utility/) (2015)
* Robert Wiblin, [A framework for comparing global problems in terms of expected impact](https://80000hours.org/articles/problem-framework/) (2016-2019)
* Benjamin Todd, [Expected value: how can we make a difference when we’re uncertain what’s true?](https://80000hours.org/articles/expected-value/) (2021-2023)
* Centre for Effective Altruism, [Expected value](https://forum.effectivealtruism.org/topics/expected-value)
* Centre for Effective Altruism, [ITN framework](https://forum.effectivealtruism.org/topics/itn-framework)
* Benjamin Todd, [What is social impact? A definition](https://80000hours.org/articles/what-is-social-impact-definition/) (2021-2023)
* Stanford Encyclopedia of Philosophy, [Normative Theories of Rational Choice: Expected Utility](https://plato.stanford.edu/entries/rationality-normative-utility/) (2014-2023)
* Amanda Askell, [Criteria of rightness vs. decision procedures](https://forum.effectivealtruism.org/posts/voDm6e6y4KHAPJeJX/act-utilitarianism-criterion-of-rightness-vs-decision) (2017)
* Аманда Аскелл, [Ценность информации и устойчивость убеждений](https://ea-ru.org/articles/the-moral-value-of-information) (2017)
* Benjamin Todd, [Cluelessness: can we know the effects of our actions?](https://80000hours.org/articles/cluelessness/) (2021)
* Centre for Effective Altruism, [Cluelessness](https://forum.effectivealtruism.org/topics/cluelessness)
* Hilary Greaves, [Cluelessness](https://philpapers.org/archive/GREC-38.pdf) (2016)
* Magnus Vinding, [Radical uncertainty about outcomes need not imply (similarly) radical uncertainty about strategies](https://magnusvinding.com/2022/09/07/strategic-uncertainty/) (2022)
* Абрам Демски, Скотт Гаррабрант, [Встроенная агентность](https://lesswrong.ru/w/%D0%92%D1%81%D1%82%D1%80%D0%BE%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D0%B0%D0%B3%D0%B5%D0%BD%D1%82%D0%BD%D0%BE%D1%81%D1%82%D1%8C) (2018)
* Magnus Vinding, [Suffering-Focused Ethics: Defense and Implications](https://magnusvinding.com/2020/05/31/suffering-focused-ethics-defense-and-implications/) (2020)
* Stefan Schubert & Lucius Caviola, [Virtues for Real-World Utilitarians](https://utilitarianism.net/guest-essays/virtues-for-real-world-utilitarians/) (2023)
* Magnus Vinding, [Research vs. non-research work to improve the world: In defense of more research and reflection](https://magnusvinding.com/2022/05/09/in-defense-of-research/) (2022)
* Стэнфордская энциклопедия философии, [Теория игр](https://reducingsuffering.github.io/245.html)
* Лукас Глор, [Критика наивного консеквенциализма](https://reducingsuffering.github.io/157.html) (2015)
* К. Кирдан, ["Цель оправдывает средства" — это и есть консеквенциализм?](https://kkirdan.github.io/blog/406.html) (2021)
* Скотт Александер, [Часто задаваемые вопросы о консеквенциализме](https://lesswrong.ru/w/%D0%A7%D0%B0%D0%92%D0%BE_%D0%BE_%D0%BA%D0%BE%D0%BD%D1%81%D0%B5%D0%BA%D0%B2%D0%B5%D0%BD%D1%86%D0%B8%D0%B0%D0%BB%D0%B8%D0%B7%D0%BC%D0%B5)
* Toby Ord, [Moral Trade](https://www.fhi.ox.ac.uk/wp-content/uploads/moral-trade-1.pdf) (2016)
* Brian Tomasik, [Gains from Trade through Compromise](https://longtermrisk.org/gains-from-trade-through-compromise/) (2013-2018)
* Teo Ajantaival, [Positive roles of life and experience in suffering-focused ethics](https://forum.effectivealtruism.org/posts/t3St6Fz4DmHtKfgqm/positive-roles-of-life-and-experience-in-suffering-focused) (2021)
* Teo Ajantaival, [Minimalist axiologies and positive lives](https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives) (2021)
* Jan Kulveit, [Deontology and virtue ethics as "effective theories" of consequentialist ethics](https://forum.effectivealtruism.org/posts/aDNPgm2v2boBbj8wK/deontology-and-virtue-ethics-as-effective-theories-of) (2022)