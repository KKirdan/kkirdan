---
layout: arbital
title: Консеквенциалистские предпочтения по умолчанию рефлексивно устойчивы
author: "Элиезер Юдковский"
original_title: Consequentialist preferences are reflectively stable by default
original_date: 2016.05.21
original: https://arbital.com/p/preference_stability/
original2: https://arbital.greaterwrong.com/p/preference_stability
translated_by: К. Кирдан
translated_when: 2024.05.16
license:
  - CC BY 3.0
  - https://creativecommons.org/licenses/by/3.0/deed.ru
excerpt: "Предположим, что Ганди не хочет, чтобы людей убивали. Представьте, что вы предлагаете Ганди таблетку, которая заставит его захотеть убивать людей. Если Ганди знает, что именно делает эта таблетка, он откажется от нее, потому что ожидает, что в результате приема такой таблетки будущий-Ганди захочет убивать людей, а затем будет их убивать, и тогда будет убито больше людей, что Ганди считает злом."
redirect: https://arbital-ru.github.io/p/preference_stability/
---
Предположим, что Ганди не хочет, чтобы людей убивали. Представьте, что вы предлагаете Ганди таблетку, которая заставит его _захотеть_ убивать людей. Если Ганди _знает_, что именно делает эта таблетка, он откажется от нее, потому что ожидает, что в результате приема такой таблетки будущий-Ганди захочет убивать людей, а затем будет их убивать, и тогда будет убито больше людей, что Ганди считает злом. По такой же логике [достаточно разумный](https://arbital.com/p/advanced_agent/) [максимизатор скрепок](paperclip-maximizer.html) — агент, который всегда выводит действие, которое, как он ожидает, приведет к наибольшему количеству скрепок — по умолчанию не будет выполнять никаких модифицирующих его действий, которые убирали бы его желание производить скрепки. Потому что в этом случае будущий-Скрепочник производил бы меньше скрепок, и в итоге скрепок в мире было бы меньше, так что нынешний-Скрепочник не оценивает такую самомодификацию как действие, которое произвело бы наибольшее ожидаемое количество будущих скрепок.

Другой способ выразить эту идею состоит в том, что защита репрезентации функции полезности и создание агентов только с такими же функциями полезности — это [конвергентные инструментальные стратегии](https://arbital.com/p/instrumental_convergence/) для консеквенциалистских агентов, которые [понимают общую картину связи](https://arbital.com/p/big_picture_awareness/) между их кодом и последствиями в реальном мире.

Хотя инструментальный _стимул_ отдавать предпочтение устойчивым предпочтениям, по-видимому, должен следовать из консеквенциализма вкупе с пониманием общей картины, менее продвинутые консеквенциалисты могут быть _неспособны_ самомодифицироваться так, чтобы сохранять понимание — они могут не понимать, какие самомодификации или конструируемые ими преемники к каким последствиям приведут. Мы могли бы рассматривать это как случай того, что «Агент не имеет в своем субъективном пространстве политик средств самосовершенствования, сохраняющих предпочтения, но хотел бы иметь такой вариант, если бы он был доступен».

То есть:

* Желание устойчивости предпочтений следует из [консеквенциализма](https://arbital.com/p/consequentialist/) вкупе с [пониманием общей картины](https://arbital.com/p/big_picture_awareness/).
* Фактическая устойчивость предпочтений, кроме того, требует наличия некоторого предварительного уровня навыка самомодификации, который может оказаться высоким, или же слишком большой осторожности в самомодификации из-за отсутствии политики, которая сохраняла бы предпочтения.
